{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking 1 : XGBoost与GBDT的区别是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：  \n",
    "XGBoost 本质上是 GBDT 的工程版本，在 GBDT 的基础上加入了许多模型的优化策略\n",
    "1. XGB 的损失函数中添加了正则化项，避免过拟合，泛化能力更好。\n",
    "2. XGB 的损失函数是用泰勒展开式展开的，不仅用到了一阶导，还是用了二阶导，可以保留更多的目标函数信息，并且加快优化速度。\n",
    "3. GBDT是给新的基模型寻找新的拟合标签（前面加法模型的负梯度），而xgboost是给新的基模型寻找新的目标函数（目标函数关于新的基模型的二阶泰勒展开）。\n",
    "4. xgboost加入了和叶子权重的L2正则化项，因而有利于模型获得更低的方差。\n",
    "5. xgboost增加了自动处理缺失值特征的策略。通过把带缺失值样本分别划分到左子树或者右子树，比较两种方案下目标函数的优劣，从而自动对有缺失值的样本进行划分，无需对缺失特征进行填充预处理。\n",
    "6. XGB 支持并行处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking 2 : 举一个你之前做过的预测例子\n",
    ">（用的什么模型，解决什么问题，比如我用LR模型，对员工离职进行了预测，效果如何... 请分享到课程微信群中）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：\n",
    "Titanic 乘客是否幸存预测  \n",
    "幸存与非幸存，是一个分类问题（也可以是一个回归问题，取决于使用的模型）  \n",
    "使用了Auto-ML，随机森林，deep-fm模型  \n",
    "初步结果 0.729 效果并不好，但随机森林的泛化能力最强，深度模型有时不一定能够得到很好的效果。  \n",
    "收获：特征决定模型的上限。特征的构造与选取，往往比模型更加重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking 3 : 请你思考，在你的工作中，需要构建哪些特征（比如用户画像，item特征...），这些特征都包括哪些维度（鼓励分享到微信群中，进行交流）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：  \n",
    "以前写过的论文：  \n",
    "碳排放权价格的影响因素主要包括市场、能源、政策三个方面   \n",
    "能源指标、政策指标、市场指标、环境指标和国外碳市场价格指标五类影响因素进行分析。  \n",
    "以月度为单位，结合经济学理论分析，充分考虑时间序列以及面板数据的特性，对各个变量进行充分的检验，  \n",
    "构造了碳排放交易权价格的影响因素模型，并使用自回归系数不同的FGLS方法进行了实证分析，  \n",
    "得到了政策因素会对碳排放交易权价格产生显著影响的结论，并给出了相关政策建议。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action 1 ：男女声音识别\n",
    ">数据集：voice.csv, 3168个录制的声音样本（来自男性和女性演讲者），  \n",
    "采集的频率范围是0hz-280hz，已经对数据进行了预处理    \n",
    "一共有21个属性值，请判断该声音是男还是女？  \n",
    "使用Accuracy作为评价标准  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、使用SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      "meanfreq    3168 non-null float64\n",
      "sd          3168 non-null float64\n",
      "median      3168 non-null float64\n",
      "Q25         3168 non-null float64\n",
      "Q75         3168 non-null float64\n",
      "IQR         3168 non-null float64\n",
      "skew        3168 non-null float64\n",
      "kurt        3168 non-null float64\n",
      "sp.ent      3168 non-null float64\n",
      "sfm         3168 non-null float64\n",
      "mode        3168 non-null float64\n",
      "centroid    3168 non-null float64\n",
      "meanfun     3168 non-null float64\n",
      "minfun      3168 non-null float64\n",
      "maxfun      3168 non-null float64\n",
      "meandom     3168 non-null float64\n",
      "mindom      3168 non-null float64\n",
      "maxdom      3168 non-null float64\n",
      "dfrange     3168 non-null float64\n",
      "modindx     3168 non-null float64\n",
      "label       3168 non-null object\n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.8+ KB\n",
      "None\n",
      "男性样本个数：1584\n",
      "女性样本个数：1584\n",
      "[1 1 1 ... 0 0 0]\n",
      "[[-4.04924806  0.4273553  -4.22490077 ... -1.43142165 -1.41913712\n",
      "  -1.45477229]\n",
      " [-3.84105325  0.6116695  -3.99929342 ... -1.41810716 -1.4058184\n",
      "  -1.01410294]\n",
      " [-3.46306647  1.60384791 -4.09585052 ... -1.42920257 -1.41691733\n",
      "  -1.06534356]\n",
      " ...\n",
      " [-1.29877326  2.32272355 -0.05197279 ... -0.5992661  -0.58671739\n",
      "   0.17588664]\n",
      " [-1.2452018   2.012196   -0.01772849 ... -0.41286326 -0.40025537\n",
      "   1.14916112]\n",
      " [-0.51474626  2.14765111 -0.07087873 ... -1.27608595 -1.2637521\n",
      "   1.47567886]]\n",
      "SVM 预测准确率：0.9826498422712934\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "#数据加载\n",
    "data = pd.read_csv(\"voice.csv\")\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "#print(data)\n",
    "# print(data.isna().sum())\n",
    "# print(data.shape)\n",
    "# print(data.describe())\n",
    "print(data.info())\n",
    "print(\"男性样本个数：{}\".format(data[data.label == 'male'].shape[0]))\n",
    "print(\"女性样本个数：{}\".format(data[data.label == 'female'].shape[0]))\n",
    "\n",
    "#分离特征值与label\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[: ,-1]\n",
    "#print(y)\n",
    "\n",
    "#标签编码\n",
    "labelencoder = LabelEncoder()\n",
    "target = labelencoder.fit_transform(y)\n",
    "print(target)\n",
    "\n",
    "#数据规范化\n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(X)\n",
    "print(X)\n",
    "\n",
    "#数据切分\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, target, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#使用 SVC(分类模型) 进行分析\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "y_pre = svc.predict(x_test)\n",
    "print(\"SVM 预测准确率：{}\".format(accuracy_score(y_test, y_pre)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、使用XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.99269\tvalidation_1-auc:0.99174\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-auc:0.99284\tvalidation_1-auc:0.99195\n",
      "[2]\tvalidation_0-auc:0.99830\tvalidation_1-auc:0.99354\n",
      "[3]\tvalidation_0-auc:0.99822\tvalidation_1-auc:0.99403\n",
      "[4]\tvalidation_0-auc:0.99818\tvalidation_1-auc:0.99409\n",
      "[5]\tvalidation_0-auc:0.99809\tvalidation_1-auc:0.99430\n",
      "[6]\tvalidation_0-auc:0.99802\tvalidation_1-auc:0.99432\n",
      "[7]\tvalidation_0-auc:0.99830\tvalidation_1-auc:0.99646\n",
      "[8]\tvalidation_0-auc:0.99823\tvalidation_1-auc:0.99647\n",
      "[9]\tvalidation_0-auc:0.99820\tvalidation_1-auc:0.99645\n",
      "[10]\tvalidation_0-auc:0.99817\tvalidation_1-auc:0.99641\n",
      "[11]\tvalidation_0-auc:0.99815\tvalidation_1-auc:0.99653\n",
      "[12]\tvalidation_0-auc:0.99811\tvalidation_1-auc:0.99654\n",
      "[13]\tvalidation_0-auc:0.99881\tvalidation_1-auc:0.99642\n",
      "[14]\tvalidation_0-auc:0.99892\tvalidation_1-auc:0.99659\n",
      "[15]\tvalidation_0-auc:0.99886\tvalidation_1-auc:0.99659\n",
      "[16]\tvalidation_0-auc:0.99892\tvalidation_1-auc:0.99662\n",
      "[17]\tvalidation_0-auc:0.99895\tvalidation_1-auc:0.99664\n",
      "[18]\tvalidation_0-auc:0.99892\tvalidation_1-auc:0.99665\n",
      "[19]\tvalidation_0-auc:0.99898\tvalidation_1-auc:0.99658\n",
      "[20]\tvalidation_0-auc:0.99896\tvalidation_1-auc:0.99657\n",
      "[21]\tvalidation_0-auc:0.99899\tvalidation_1-auc:0.99648\n",
      "[22]\tvalidation_0-auc:0.99900\tvalidation_1-auc:0.99643\n",
      "[23]\tvalidation_0-auc:0.99899\tvalidation_1-auc:0.99637\n",
      "[24]\tvalidation_0-auc:0.99898\tvalidation_1-auc:0.99639\n",
      "[25]\tvalidation_0-auc:0.99916\tvalidation_1-auc:0.99639\n",
      "[26]\tvalidation_0-auc:0.99915\tvalidation_1-auc:0.99634\n",
      "[27]\tvalidation_0-auc:0.99914\tvalidation_1-auc:0.99633\n",
      "[28]\tvalidation_0-auc:0.99925\tvalidation_1-auc:0.99630\n",
      "Stopping. Best iteration:\n",
      "[18]\tvalidation_0-auc:0.99892\tvalidation_1-auc:0.99665\n",
      "\n",
      "准确率为:0.9668769716088328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10109\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model1 = xgb.XGBClassifier(max_depth = 15,\n",
    "                          n_estimators = 10000, \n",
    "                          colsample_bytree=0.8, \n",
    "                          subsample=0.9,\n",
    "                          eta=0.01,  \n",
    "                          seed=42)\n",
    "\n",
    "model1 = model1.fit(x_train, y_train, \n",
    "                  eval_metric='auc', \n",
    "                  eval_set=[(x_train, y_train), (x_test, y_test)],\n",
    "                  verbose=True, #早停法，如果auc在10epoch没有进步就stop\n",
    "                  early_stopping_rounds=10)\n",
    "\n",
    "\n",
    "y_pre = model1.predict(x_test)\n",
    "print(\"准确率为:{}\".format(accuracy_score(y_test, y_pre)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:36:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { boosting_type, subsample_freq } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.99195\ttest-auc:0.98811\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 200 rounds.\n",
      "[25]\ttrain-auc:0.99928\ttest-auc:0.99650\n",
      "[50]\ttrain-auc:0.99942\ttest-auc:0.99643\n",
      "[75]\ttrain-auc:0.99963\ttest-auc:0.99747\n",
      "[100]\ttrain-auc:0.99972\ttest-auc:0.99740\n",
      "[125]\ttrain-auc:0.99977\ttest-auc:0.99750\n",
      "[150]\ttrain-auc:0.99982\ttest-auc:0.99750\n",
      "[175]\ttrain-auc:0.99986\ttest-auc:0.99741\n",
      "[200]\ttrain-auc:0.99990\ttest-auc:0.99734\n",
      "[225]\ttrain-auc:0.99992\ttest-auc:0.99740\n",
      "[250]\ttrain-auc:0.99994\ttest-auc:0.99749\n",
      "Stopping. Best iteration:\n",
      "[56]\ttrain-auc:0.99947\ttest-auc:0.99762\n",
      "\n",
      "准确率为:0.9747634069400631\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "#数据加载\n",
    "data = pd.read_csv(\"voice.csv\")\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "\n",
    "#分离特征值与label\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[: ,-1]\n",
    "#print(y)\n",
    "\n",
    "#标签编码\n",
    "labelencoder = LabelEncoder()\n",
    "target = labelencoder.fit_transform(y)\n",
    "# print(target)\n",
    "\n",
    "#数据规范化\n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(X)\n",
    "# print(X)\n",
    "\n",
    "#数据切分\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, target, test_size = 0.2, random_state = 42)\n",
    "#设置参数\n",
    "param = {'boosting_type':'gbdt',\n",
    "                         'objective' : 'binary:logistic', #\n",
    "                         'eval_metric' : 'auc',\n",
    "                         'eta' : 0.01,\n",
    "                         'max_depth' : 15,\n",
    "                         'colsample_bytree':0.8,\n",
    "                         'subsample': 0.9,\n",
    "                         'subsample_freq': 8,\n",
    "                         'alpha': 0.6,\n",
    "                         'lambda': 0,\n",
    "                         'seed':42\n",
    "        }\n",
    "\n",
    "#转换数据结构\n",
    "train_data = xgb.DMatrix(x_train, label = y_train)\n",
    "test_data = xgb.DMatrix(x_test, label = y_test)\n",
    "test = xgb.DMatrix(x_test)\n",
    "model2 = xgb.train(param, train_data, evals=[(train_data, 'train'), (test_data, 'test')], num_boost_round = 10000, early_stopping_rounds=200, verbose_eval=25)\n",
    "y_predict = model2.predict(test)\n",
    "\n",
    "#转化为二分类\n",
    "predict = pd.DataFrame(y_predict, columns = [\"y_pre\"])\n",
    "predict[\"y_pre\"] = predict[\"y_pre\"].map(lambda x:1 if x>=0.5 else 0)\n",
    "print(\"准确率为:{}\".format(accuracy_score(y_test, predict[\"y_pre\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本章任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "[text:'工具', text:'LR工具使用']\n",
      "[text:'工具', text:'SVM工具使用']\n",
      "[text:'原理', text:'FM模型：FM，FFM，DeepFM，NFM，AFM']\n",
      "[text:'原理', text:'LR优点及缺点']\n",
      "[text:'原理', text:'SVM优点及缺点']\n",
      "[text:'原理', text:'FM与LR区别']\n",
      "[text:'原理', text:'FM与SVM区别']\n",
      "[text:'原理', text:'三种方式：Bagging, Boosting, Stacking']\n",
      "[text:'原理', text:'XGBoost原理']\n",
      "[text:'原理', text:'LightGBM = XGBoost + Histogram + GOSS + EFB']\n",
      "[text:'原理', text:'CatBoost = Catgorical + Boost']\n",
      "[text:'原理', text:'自然梯度理解']\n",
      "[text:'工具', text:'XGBoost，LightGBM, CatBoost工具使用']\n",
      "[text:'工具', text:'调试工程 Debug能力']\n",
      "[text:'Thinking1', text:'XGBoost与GBDT的区别是什么？'] text:'简要说明这两者之间的区别（10points）'\n",
      "[text:'Thinking1', text:'举一个你之前做过的预测例子（用的什么模型，解决什么问题，比如我用LR模型，对员工离职进行了预测，效果如何... 请分享到课程微信群中）'] text:'简要说明之前做过的例子，用的模型，解决的问题，并且在群里分享（10points）'\n",
      "[text:'Thinking2', text:'请你思考，在你的工作中，需要构建哪些特征（比如用户画像，item特征...），这些特征都包括哪些维度（鼓励分享到微信群中，进行交流）'] text:'能对工作场景，以及构造的特征进行洞察，在班级群中分享（10points）'\n",
      "[text:'Action1', text:'男女声音识别\\n数据集：voice.csv\\n3168个录制的声音样本（来自男性和女性演讲者），采集的频率范围是0hz-280hz，已经对数据进行了预处理\\n一共有21个属性值，请判断该声音是男还是女？\\n使用Accuracy作为评价标准\\n'] text:'1、完成代码（30points）\\n2、分享经验（30points）\\n3、得分Top3（10points）'\n"
     ]
    }
   ],
   "source": [
    "import xlrd\n",
    "data = xlrd.open_workbook('L6自测文档.xls')\n",
    "#通过索引顺序获取\n",
    "table = data.sheet_by_index(0)\n",
    "\n",
    "\"\"\" 工作表中行/列的操作 \"\"\"\n",
    "#获取该sheet中的有效行数\n",
    "nrows = table.nrows  \n",
    "print(nrows)\n",
    "row_index, col_index = 0, 0\n",
    "# 获取某行信息\n",
    "for row_index in range(2, nrows-5):\n",
    "    print(table.row(row_index)[:2])\n",
    "for row_index in range(nrows-4, nrows):\n",
    "    print(table.row(row_index)[:2], table.row(row_index)[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking 1 : CNN 的参数共享指的是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：  \n",
    "CNN 的主要特点是：先进行特征提取（feature extraction）得到 Feature map 然后放入全连接层进行学习。  \n",
    "CNN 的参数共享指的是使用卷积核在图像的不同位置进行特征提取时，卷积核（权重）是不变的，以此使用不同的卷积核得到图像不同维度的 Feature Map。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking 2 ：为什么会用到batch normalization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：  \n",
    "Batch-Normalization：在每一批的数据进行卷积前，都进行一次标准化处理。 （由于数据量大，无法全部放进去，因此进行分批处理） \n",
    "1. 由于卷积神经网络层级比较大，出现一定的偏差就会造成深度学习时每一层都会存在偏差，造成深度学习的效率变慢，因此为了提高学习的效率，在每一次卷积前都做一次标准化。\n",
    "2. BN 通过标准化将数据规范到 N（0，1）的正态分布水平，使得非线性函数的输入值在一个敏感范围内, 缓解梯度消失的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking 3 ：使用dropout可以解决什么问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：  \n",
    "关闭某些神经元，防止过拟合问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action 1 ： 使用任何神经网络框架，对CIFAR-10进行分类\n",
    ">http://www.cs.toronto.edu/~kriz/cifar.html  \n",
    "训练集 50000，测试集 10000  \n",
    "图像大小 32*32 彩色  \n",
    "10个分类：ariplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "#数据加载\n",
    "train_data = datasets.CIFAR10(root = 'C:/nas/cifar10/', train = True, transform = transforms.ToTensor(), download = True)\n",
    "test_data = datasets.CIFAR10(root = 'C:/nas/cifar10/', train = False, transform = transforms.ToTensor(), download = True)\n",
    "#定义超参数\n",
    "EPOCH = 60\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.001\n",
    "\n",
    "# 使用dataloader 进行分批\n",
    "train_loader = DataLoader(dataset = train_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = BATCH_SIZE)\n",
    "\n",
    "#使用 denseNet\n",
    "model = torchvision.models.densenet121(pretrained = True)\n",
    "\n",
    "# 预训练会下载一个文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 loss0.5672690272331238 time40.95031452178955\n",
      "epoch2 loss0.5810059905052185 time40.27595400810242\n",
      "epoch3 loss0.34251824021339417 time40.63038897514343\n",
      "epoch4 loss0.27401426434516907 time41.32640528678894\n",
      "epoch5 loss0.26239970326423645 time40.442259550094604\n",
      "epoch6 loss0.24376359581947327 time40.674166679382324\n",
      "epoch7 loss0.3113354742527008 time40.59865212440491\n",
      "epoch8 loss0.33181753754615784 time40.707913637161255\n",
      "epoch9 loss0.12041361629962921 time40.71990156173706\n",
      "epoch10 loss0.09377484768629074 time41.26325750350952\n",
      "epoch11 loss0.07072024047374725 time40.723472356796265\n",
      "epoch12 loss0.14862391352653503 time40.74365782737732\n",
      "epoch13 loss0.18139901757240295 time40.75734996795654\n",
      "epoch14 loss0.21069887280464172 time40.99097990989685\n",
      "epoch15 loss0.13860833644866943 time44.604464292526245\n",
      "epoch16 loss0.12817427515983582 time43.88355207443237\n",
      "epoch17 loss0.12013576924800873 time43.3668212890625\n",
      "epoch18 loss0.038227397948503494 time41.96275305747986\n",
      "epoch19 loss0.1915787160396576 time42.42320537567139\n",
      "epoch20 loss0.036156922578811646 time42.08519983291626\n",
      "epoch21 loss0.09259611368179321 time42.261706829071045\n",
      "epoch22 loss0.040149345993995667 time41.97190451622009\n",
      "epoch23 loss0.09441657364368439 time42.201984167099\n",
      "epoch24 loss0.18603567779064178 time42.20182180404663\n",
      "epoch25 loss0.02768629416823387 time42.3330659866333\n",
      "epoch26 loss0.04044588655233383 time43.582895278930664\n",
      "epoch27 loss0.033461794257164 time47.8920361995697\n",
      "epoch28 loss0.09956257045269012 time43.46480965614319\n",
      "epoch29 loss0.22065477073192596 time41.47848033905029\n",
      "epoch30 loss0.0596761628985405 time54.006203174591064\n",
      "epoch31 loss0.19085726141929626 time61.02040410041809\n",
      "epoch32 loss0.06993778049945831 time60.863630294799805\n",
      "epoch33 loss0.005105651915073395 time61.072975635528564\n",
      "epoch34 loss0.01644488424062729 time61.440237045288086\n",
      "epoch35 loss0.04960503801703453 time61.05123686790466\n",
      "epoch36 loss0.028162673115730286 time59.888333559036255\n",
      "epoch37 loss0.10495865345001221 time60.451858043670654\n",
      "epoch38 loss0.004215448163449764 time60.26576638221741\n",
      "epoch39 loss0.013946324586868286 time62.67062568664551\n",
      "epoch40 loss0.052815794944763184 time60.8343551158905\n",
      "epoch41 loss0.19168207049369812 time61.26508593559265\n",
      "epoch42 loss0.08781862258911133 time60.36656665802002\n",
      "epoch43 loss0.017311546951532364 time60.400909185409546\n",
      "epoch44 loss0.06491662561893463 time61.25174903869629\n",
      "epoch45 loss0.026704123243689537 time62.32893991470337\n",
      "epoch46 loss0.08913011848926544 time61.22710037231445\n",
      "epoch47 loss0.0008140932768583298 time61.30861949920654\n",
      "epoch48 loss0.004926904104650021 time62.50662040710449\n",
      "epoch49 loss0.02887289598584175 time43.13043189048767\n",
      "epoch50 loss0.020024392753839493 time44.02690362930298\n",
      "epoch51 loss0.17913343012332916 time46.14087414741516\n",
      "epoch52 loss0.0071393633261322975 time42.13630986213684\n",
      "epoch53 loss0.009067469276487827 time43.04072976112366\n",
      "epoch54 loss0.05252482369542122 time66.68712210655212\n",
      "epoch55 loss0.034628771245479584 time60.801403760910034\n",
      "epoch56 loss0.3426566421985626 time60.3052761554718\n",
      "epoch57 loss0.02785966359078884 time60.89253544807434\n",
      "epoch58 loss0.04533080756664276 time62.45083689689636\n",
      "epoch59 loss0.000625183864030987 time60.24009847640991\n",
      "epoch60 loss0.00033324488322250545 time61.359872579574585\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr = LR)\n",
    "\n",
    "#定义device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 训练\n",
    "for epoch in range(EPOCH):\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #前向传播\n",
    "        outputs = model(inputs)\n",
    "        # 计算损失函数\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        #参数更新\n",
    "        optimizer.step()\n",
    "    print('epoch{} loss{} time{}'.format(epoch + 1, loss.item(), time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10_densenet121epoch60lr0.001batch256.pt saved\n"
     ]
    }
   ],
   "source": [
    "# 保存训练的模型\n",
    "file_name = 'cifar10_densenet121epoch60lr0.001batch256.pt'\n",
    "torch.save(model, file_name)\n",
    "print(file_name+' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000张图像的准确率：86.41\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "model = torch.load(file_name)\n",
    "model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    #前向传播\n",
    "    out = model(images)\n",
    "    #越策结果\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    # 判断预测结果与实际结果是否一致\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "#输出识别率\n",
    "print('10000张图像的准确率：{}'.format(100.0 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 loss0.05031668022274971 time42.50939679145813\n",
      "epoch2 loss0.0178708303719759 time42.61570858955383\n",
      "epoch3 loss0.014036168344318867 time42.92334794998169\n",
      "epoch4 loss0.01648365892469883 time42.898672342300415\n",
      "epoch5 loss0.01879817806184292 time42.734074115753174\n",
      "epoch6 loss0.0004975419724360108 time42.67076230049133\n",
      "epoch7 loss0.0010417394805699587 time42.75729203224182\n",
      "epoch8 loss0.2045796811580658 time42.63768911361694\n",
      "epoch9 loss0.058820534497499466 time42.666391372680664\n",
      "epoch10 loss0.061279989778995514 time43.433658838272095\n",
      "epoch11 loss0.07710004597902298 time43.35028386116028\n",
      "epoch12 loss0.008122741244733334 time44.06403660774231\n",
      "epoch13 loss0.043019261211156845 time45.71465611457825\n",
      "epoch14 loss0.03414652496576309 time57.12015986442566\n",
      "epoch15 loss0.059438031166791916 time64.43510603904724\n",
      "epoch16 loss0.034043531864881516 time60.98513436317444\n",
      "epoch17 loss0.02369821071624756 time60.59696173667908\n",
      "epoch18 loss0.002959128934890032 time60.161499977111816\n",
      "epoch19 loss0.0873163565993309 time59.74687933921814\n",
      "epoch20 loss0.015334774740040302 time61.05882978439331\n",
      "epoch21 loss0.07713203132152557 time60.14448857307434\n",
      "epoch22 loss0.002429382409900427 time60.41040635108948\n",
      "epoch23 loss0.0053961812518537045 time59.75466322898865\n",
      "epoch24 loss0.0029435923788696527 time60.28793740272522\n",
      "epoch25 loss0.0031441717874258757 time60.44423770904541\n",
      "epoch26 loss0.002445894293487072 time60.61463975906372\n",
      "epoch27 loss0.010707627981901169 time60.59755825996399\n",
      "epoch28 loss0.003767904592677951 time61.06108856201172\n",
      "epoch29 loss0.057025808840990067 time59.59097981452942\n",
      "epoch30 loss0.002735954476520419 time61.09450721740723\n",
      "epoch31 loss0.007143058814108372 time59.759215116500854\n",
      "epoch32 loss0.10361107438802719 time59.761075019836426\n",
      "epoch33 loss0.01191104669123888 time56.40263247489929\n",
      "epoch34 loss0.005262013059109449 time43.34810543060303\n",
      "epoch35 loss0.00045159910223446786 time43.111061096191406\n",
      "epoch36 loss0.007872447371482849 time43.96240544319153\n",
      "epoch37 loss0.010069138370454311 time46.481637954711914\n",
      "epoch38 loss0.08915651589632034 time41.48871612548828\n",
      "epoch39 loss0.008734175935387611 time41.812198638916016\n",
      "epoch40 loss0.03532639145851135 time41.43181657791138\n"
     ]
    }
   ],
   "source": [
    "file_name = 'cifar10_densenet121epoch60lr0.001batch256.pt'\n",
    "model = torch.load(file_name)\n",
    "\n",
    "EPOCH = 40\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.001\n",
    "\n",
    "import time\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr = LR)\n",
    "\n",
    "#定义device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 训练\n",
    "for epoch in range(EPOCH):\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #前向传播\n",
    "        outputs = model(inputs)\n",
    "        # 计算损失函数\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        #参数更新\n",
    "        optimizer.step()\n",
    "    print('epoch{} loss{} time{}'.format(epoch + 1, loss.item(), time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10_densenet121epoch100lr0.001batch256.pt saved\n"
     ]
    }
   ],
   "source": [
    "# 保存训练的模型\n",
    "file_name = 'cifar10_densenet121epoch100lr0.001batch256.pt'\n",
    "torch.save(model, file_name)\n",
    "print(file_name+' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000张图像的准确率：85.63\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "model = torch.load(file_name)\n",
    "model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    #前向传播\n",
    "    out = model(images)\n",
    "    #越策结果\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    # 判断预测结果与实际结果是否一致\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "#输出识别率\n",
    "print('10000张图像的准确率：{}'.format(100.0 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA out memery:\n",
    "```python\n",
    "#查看进程\n",
    "nvidia-smi\n",
    "# 关闭进程\n",
    "taskkill -PID 进程号 -F \n",
    "```\n",
    "## 参考：DenseNet 源码构造方式https://www.pianshen.com/article/5919349111/  \n",
    "## 原论文：https://arxiv.org/pdf/1707.06990.pdf&gt;%60_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本章任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "[text:'原理', text:'传统图像识别模型']\n",
      "[text:'原理', text:'CNN的由来']\n",
      "[text:'原理', text:'局部感受野，共享权重，池化']\n",
      "[text:'原理', text:'平移不变与空间不变特性']\n",
      "[text:'原理', text:'卷积核的作用']\n",
      "[text:'原理', text:'Batch Normalization']\n",
      "[text:'原理', text:'Pooling与Dropout']\n",
      "[text:'工具', text:'AlexNet原理及使用']\n",
      "[text:'原理', text:'DenseNet原理'] empty:''\n",
      "[text:'课下思考与练习', empty:''] empty:''\n",
      "[text:'Thinking2', text:'参数共享指的是什么？'] text:'能简要说明他们的作用（10points）\\n'\n",
      "[text:'Thinking3', text:'为什么会用到batch normalization ?'] text:'能简要说明BN的作用（10points）'\n",
      "[text:'Thinking4', text:'使用dropout可以解决什么问题？'] text:'能简要解决的问题（10points）'\n",
      "[text:'Action1', text:'使用任何神经网络框架，对CIFAR-10进行分类\\nhttp://www.cs.toronto.edu/~kriz/cifar.html\\n训练集 50000，测试集 10000\\n图像大小 32*32 彩色\\n10个分类：ariplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck'] text:'1、完成代码（30points）\\n2、使用ResNet, DenseNet或其他网络（20points）\\n3、Accuracy >90% （20points）'\n"
     ]
    }
   ],
   "source": [
    "import xlrd\n",
    "data = xlrd.open_workbook('L7-2自测文档.xls')\n",
    "#通过索引顺序获取\n",
    "table = data.sheet_by_index(0)\n",
    "\n",
    "\"\"\" 工作表中行/列的操作 \"\"\"\n",
    "#获取该sheet中的有效行数\n",
    "nrows = table.nrows  \n",
    "print(nrows)\n",
    "row_index, col_index = 0, 0\n",
    "# 获取某行信息\n",
    "for row_index in range(2, nrows-7):\n",
    "    print(table.row(row_index)[:2])\n",
    "for row_index in range(nrows-6, nrows):\n",
    "    print(table.row(row_index)[:2], table.row(row_index)[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
